a[3]$Accuracy
class(a[3])
a[3]
a$overall
a$overall[1]
class(a$overall)
names(a$overall)
a$overall$Accuracy
aa<-a$overall
aa$Accuracy
aa[1]
class(aa[1])
aa[1][1]
length(aa)
length(a)
a
a[3]
length(a$overall)
length(aa)
aa
length(aa[1])
class(aa[1])
aa[1]
paste("PCA = ",aa[1])
paste("PCA = ",a$overall[1])
?data.frame
il<-grep("^IL",colnames(training))
iltrain<-data.frame(diagnosis=training$diagnosis,training[,il])
iltest<-data.frame(diagnosis=testing$diagnosis,testing[,il])
#build predictive model using the predictors as they are
modelFit<-train(iltrain$diagnosis~., data=iltrain, method="glm")
head(iltest[,1])
cm<-confusionMatrix(iltest[,1],predict(modelFit,iltest))
cm
#build predictive model using PCA with principal components explaining 80% of the variance in the predictors
preProc<-preProcess(iltrain[,-1],method="pca", thresh=0.8)
trainPC<-predict(preProc,iltrain[,-1])
modelFit<-train(iltrain[,1]~., method="glm", data=trainPC)
testPC<-predict(preProc,iltest[,-1])
cmPCA<-confusionMatrix(iltest[,1],predict(modelFit,testPC))
cmPCA
#result
data.frame(row.names=c("Non-PCA Accuracy: ", "PCA Accuracy: "), round(cm$overall[1],2), round(cmPCA$overall[1],2))
il<-grep("^IL",colnames(training))
iltrain<-data.frame(diagnosis=training$diagnosis,training[,il])
iltest<-data.frame(diagnosis=testing$diagnosis,testing[,il])
#build predictive model using the predictors as they are
modelFit<-train(iltrain$diagnosis~., data=iltrain, method="glm")
head(iltest[,1])
cm<-confusionMatrix(iltest[,1],predict(modelFit,iltest))
cm
#build predictive model using PCA with principal components explaining 80% of the variance in the predictors
preProc<-preProcess(iltrain[,-1],method="pca", thresh=0.8)
trainPC<-predict(preProc,iltrain[,-1])
modelFit<-train(iltrain[,1]~., method="glm", data=trainPC)
testPC<-predict(preProc,iltest[,-1])
cmPCA<-confusionMatrix(iltest[,1],predict(modelFit,testPC))
cmPCA
#result
data.frame(row.names=c("Non-PCA", "PCA"), round(cm$overall[1],2), round(cmPCA$overall[1],2))
il<-grep("^IL",colnames(training))
iltrain<-data.frame(diagnosis=training$diagnosis,training[,il])
iltest<-data.frame(diagnosis=testing$diagnosis,testing[,il])
#build predictive model using the predictors as they are
modelFit<-train(iltrain$diagnosis~., data=iltrain, method="glm")
head(iltest[,1])
cm<-confusionMatrix(iltest[,1],predict(modelFit,iltest))
cm
#build predictive model using PCA with principal components explaining 80% of the variance in the predictors
preProc<-preProcess(iltrain[,-1],method="pca", thresh=0.8)
trainPC<-predict(preProc,iltrain[,-1])
modelFit<-train(iltrain[,1]~., method="glm", data=trainPC)
testPC<-predict(preProc,iltest[,-1])
cmPCA<-confusionMatrix(iltest[,1],predict(modelFit,testPC))
cmPCA
#result
data.frame(round(cm$overall[1],2), round(cmPCA$overall[1],2))
il<-grep("^IL",colnames(training))
iltrain<-data.frame(diagnosis=training$diagnosis,training[,il])
iltest<-data.frame(diagnosis=testing$diagnosis,testing[,il])
#build predictive model using the predictors as they are
modelFit<-train(iltrain$diagnosis~., data=iltrain, method="glm")
head(iltest[,1])
cm<-confusionMatrix(iltest[,1],predict(modelFit,iltest))
cm
#build predictive model using PCA with principal components explaining 80% of the variance in the predictors
preProc<-preProcess(iltrain[,-1],method="pca", thresh=0.8)
trainPC<-predict(preProc,iltrain[,-1])
modelFit<-train(iltrain[,1]~., method="glm", data=trainPC)
testPC<-predict(preProc,iltest[,-1])
cmPCA<-confusionMatrix(iltest[,1],predict(modelFit,testPC))
cmPCA
#result
data.frame("Non-PCA"=round(cm$overall[1],2), "PCA"=round(cmPCA$overall[1],2))
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
table(dim(training),dim(testing))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
table(dim(training),dim(testing))
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data.frame(dim(training),dim(testing))
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data.frame(row.names=c("rows","columns"),training=dim(training),testing=dim(testing))
167+166
dim(adData)
il<-grep("^IL",colnames(training))
iltrain<-data.frame(diagnosis=training$diagnosis,training[,il])
iltest<-data.frame(diagnosis=testing$diagnosis,testing[,il])
#build predictive model using the predictors as they are
modelFit<-train(iltrain$diagnosis~., data=iltrain, method="glm")
cm<-confusionMatrix(iltest[,1],predict(modelFit,iltest))
cm
#build predictive model using PCA with principal components explaining 80% of the variance in the predictors
preProc<-preProcess(iltrain[,-1],method="pca", thresh=0.8)
trainPC<-predict(preProc,iltrain[,-1])
modelFit<-train(iltrain[,1]~., method="glm", data=trainPC)
testPC<-predict(preProc,iltest[,-1])
cmPCA<-confusionMatrix(iltest[,1],predict(modelFit,testPC))
cmPCA
#result
data.frame(Non-PCA=round(cm$overall[1],2), PCA=round(cmPCA$overall[1],2))
il<-grep("^IL",colnames(training))
iltrain<-data.frame(diagnosis=training$diagnosis,training[,il])
iltest<-data.frame(diagnosis=testing$diagnosis,testing[,il])
#build predictive model using the predictors as they are
modelFit<-train(iltrain$diagnosis~., data=iltrain, method="glm")
cm<-confusionMatrix(iltest[,1],predict(modelFit,iltest))
cm
#build predictive model using PCA with principal components explaining 80% of the variance in the predictors
preProc<-preProcess(iltrain[,-1],method="pca", thresh=0.8)
trainPC<-predict(preProc,iltrain[,-1])
modelFit<-train(iltrain[,1]~., method="glm", data=trainPC)
testPC<-predict(preProc,iltest[,-1])
cmPCA<-confusionMatrix(iltest[,1],predict(modelFit,testPC))
cmPCA
#result
data.frame("Non-PCA"=round(cm$overall[1],2), "PCA"=round(cmPCA$overall[1],2))
#correlated predictors
M<-abs(cor(training[,-58]))
M[1:7,1:7]
diag(M)<-0
cp<-which(M>0.8, arr.ind=TRUE)
cp #correlated predictors
par(mfrow=c(2,2))
plot(training[,cp[1,]])
plot(training[,cp[2,]])
#plot(training[,cp[3,]])
plot(training[,cp[4,]])
smallTrain<-training[,c(34,32)]
prComp1<-prcomp(smallTrain) #singular value decomposition (SVD)
prComp1
plot(prComp1$x[,1],prComp1$x[,2], xlab="PC1",ylab="PC2")
typeColor<-((training$type=="spam")*1+1)
prComp<-prcomp(log10(training[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc<-preProcess(log10(training[,-58]+1), method="pca", pcaComp=2)
trainPC<-predict(preProc,log10(training[,-58]+1))
plot(trainPC[,1],trainPC[,2],col=typeColor)
source('~/.active-rstudio-document', echo=TRUE)
#correlated predictors
M<-abs(cor(training[,-58]))
M[1:7,1:7]
diag(M)<-0
cp<-which(M>0.8, arr.ind=TRUE)
cp #correlated predictors
par(mfrow=c(2,2))
plot(training[,cp[1,]])
plot(training[,cp[2,]])
#plot(training[,cp[3,]])
plot(training[,cp[4,]])
smallTrain<-training[,c(34,32)]
prComp1<-prcomp(smallTrain) #singular value decomposition (SVD)
prComp1
plot(prComp1$x[,1],prComp1$x[,2], xlab="PC1",ylab="PC2")
typeColor<-((training$type=="spam")*1+1)
prComp<-prcomp(log10(training[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc<-preProcess(log10(training[,-58]+1), method="pca", pcaComp=2)
trainPC<-predict(preProc,log10(training[,-58]+1))
plot(trainPC[,1],trainPC[,2],col=typeColor)
prComp<-prcomp(log10(training[,-58]+1))
prComp<-prcomp(log10(training[,-58]))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
hist(training$Superplasticizer)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
il<-grep("^IL",colnames(training))
preProc<-preProcess(training[,il],method="pca")
preProc
preProc$numComp
?preProcess
il<-grep("^IL",colnames(training))
preProc<-preProcess(training[,il],method="pca",thresh=0.8)
preProc
preProc$numComp
head(training[,il])
?which
il<-grep("^IL",colnames(training))
preProc<-preProcess(training[,il],method="pca",thresh=0.8)
preProc
preProc$numComp
#alternative method
M<-abs(cor(training[,il]))
diag(M)<-0
which(M>0.8, arr.ind=TRUE)
which(M>0.7, arr.ind=TRUE)
preProc
il<-grep("^IL",colnames(training))
preProc<-preProcess(training[,il],method="pca",thresh=0.9)
preProc
preProc$numComp
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
ccs<-cut2(training$CompressiveStrength,g=4)
par(mfrow=c(1,2))
#featurePlot(x=training,y=training$CompressiveStrength,plot="pairs")
plot(training$CompressiveStrength, col=training$Age)
plot(training$FlyAsh, col=ccs)
#plot(training$FlyAsh)
#boxplot(ccs,training$Age, col="pink")
print("3. There is a step-like pattern in the plot of outcome versus index in the training set.")
getwd()
setwd("DDP-project/wage")
runApp()
library(shiny)
runApp()
deployApp()
library(shinyapps)
deployApp()
library(slidify)
install_github('slidify', 'ramnathv')
library(devtools)
install_github('slidify', 'ramnathv')
library(slidify)
setwd("slidify")
getwd()
setwd("../slidify")
author("wage")
setwd("..")
getwd()
setwd("slidify")
setwd("wage")
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices=list("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9), selected=2),
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in choices){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-list("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9), selected=2),
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in choices){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-list("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9), selected=2)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in choices){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-data.frame("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9), selected=2)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in choices){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-data.frame("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9), selected=2)
print(choices)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in choices){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
c<-data.frame("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9), selected=2)
print(choices)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in choices){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
c<-data.frame("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9), selected=2)
print(c)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in choices){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-data.frame("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9), selected=2)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in length(choices)){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-data.frame("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
for (i in length(choices)){
x1<-Wage[,as.numeric(i)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
}
slidify("index.Rmd")
install_github('slidifyLibraries', 'ramnathv')
slidify("index.Rmd")
slidify("index.Rmd")
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-data.frame("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
x1<-Wage[,as.numeric(2)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=150
x1<-Wage[,as.numeric(2)]
plot(x1, Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=50
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
?par
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-data.frame("year"=1, "age"=2, "sex"=3, "maritl"=4, "race"=5,
"education"=6, "job class"=8, "health"=9)
mw<-mean(Wage$wage)
md<-median(Wage$wage)
par(cex.axis=0.8)
plot(Wage[,as.numeric(2)], Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=50
slidify("index.Rmd")
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
choices<-c("year", "age", "sex", "maritl", "race",
"education", "job class", "health")
mw<-mean(Wage$wage)
md<-median(Wage$wage)
par(cex.axis=0.8)
plot(Wage[,choices[2], Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=50
plot(Wage[,choices[2]], Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=50
plot(Wage[,choices[6]], Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=50
plot(Wage[,choices[6]], Wage$wage, xlab='', ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=50
plot(Wage[,choices[6]], Wage$wage, xlab=choices[6], ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=50
plot(Wage[,choices[2]], Wage$wage, xlab=choices[2], ylab="wage", main ='Wage')
lines(c(0,100), c(mw,mw), col="red", lwd =3)
width=50
slidify("index.Rmd")
publish_github(chiccueri, wage)
publish_github(chiccueri, wage)
publish_github(wage, chiccueri)
publish_github(wage, username=getOption("github.chiccueri"))
publish_github(wage, username=getOption("github.chiccueri"))
publish(user=chiccueri, repo=wage)
publish_github("chiccueri", "wage")
publish_github("wage", username=getOption("github.chiccueri"))
publish(user="chiccueri", repo="wage")
publish(user="chiccueri/github.io", repo="wage")
publish(user="chiccueri/chiccueri/github.io", repo="wage")
publish(user="chiccueri", repo="wage")
publish_github("chiccueri", "wage")
?abline
?runif
runif(100,-3,3)
plot(dunif(100,-3,3))
x<-runif(100,-3,3)
y<-runif(100,-3,3)
plot(x,y)
y<-runif(100,-1,1)
plot(x,y)
y<-runif(100,1,2)
y<-runif(100,1.9,2)
plot(x,y)
abline(lm(y~x))
plot(x,resid(lm(y~x)))
y<-rnorm(100)
plot(x,y)
x<-runif(100,0,6)
y<-rnorm(100)
plot(x,y)
hist(y)
plot(y)
plot(x,y)
y<-rnorm(100,0,0.001)
plot(x,y)
y<-rnorm(100,0,0.001*x)
plot(x,y)
y<-x+rnorm(100,0,0.001)
plot(x,y)
plot(x,resid(lm(y~x)))
y<-x+rnorm(100,0,0.001*x)
plot(x,y)
plot(x,resid(lm(y~x)))
abline(h=0)
